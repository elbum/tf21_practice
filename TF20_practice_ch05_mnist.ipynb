{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "VDH43aYMx7vX",
    "outputId": "6db06d8c-80ec-4f22-f68f-3120da0040b1"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "  %tensorflow_version 2.x\n",
    "except Exception:\n",
    "  pass\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 11486039964104904889\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 9204972913\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 7629801697969448868\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib;print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 179
    },
    "colab_type": "code",
    "id": "uU4ll7vCx_vT",
    "outputId": "6e393993-bf6a-436e-cddd-c192a0638a95"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
      "32768/29515 [=================================] - 0s 2us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
      "26427392/26421880 [==============================] - 4s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
      "8192/5148 [===============================================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
      "4423680/4422102 [==============================] - 3s 1us/step\n",
      "60000 10000\n"
     ]
    }
   ],
   "source": [
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "(train_X , train_Y ) , (test_X , test_Y) = fashion_mnist.load_data()\n",
    "print(len(train_X),len(test_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "colab_type": "code",
    "id": "8EqWOQAEyQhD",
    "outputId": "6bcc2a3f-4c77-4116-c209-8d15cc4e8152"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(train_X[0],cmap='Accent')\n",
    "\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "7Z4R38bny8kF",
    "outputId": "a0bb4b26-62aa-4cbd-a031-e8e89a690dc7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,\n",
       "          0,   0,  13,  73,   0,   0,   1,   4,   0,   0,   0,   0,   1,\n",
       "          1,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
       "          0,  36, 136, 127,  62,  54,   0,   0,   0,   1,   3,   4,   0,\n",
       "          0,   3],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   6,\n",
       "          0, 102, 204, 176, 134, 144, 123,  23,   0,   0,   0,   0,  12,\n",
       "         10,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0, 155, 236, 207, 178, 107, 156, 161, 109,  64,  23,  77, 130,\n",
       "         72,  15],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   0,\n",
       "         69, 207, 223, 218, 216, 216, 163, 127, 121, 122, 146, 141,  88,\n",
       "        172,  66],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   1,   1,   0,\n",
       "        200, 232, 232, 233, 229, 223, 223, 215, 213, 164, 127, 123, 196,\n",
       "        229,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "        183, 225, 216, 223, 228, 235, 227, 224, 222, 224, 221, 223, 245,\n",
       "        173,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "        193, 228, 218, 213, 198, 180, 212, 210, 211, 213, 223, 220, 243,\n",
       "        202,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   3,   0,  12,\n",
       "        219, 220, 212, 218, 192, 169, 227, 208, 218, 224, 212, 226, 197,\n",
       "        209,  52],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   6,   0,  99,\n",
       "        244, 222, 220, 218, 203, 198, 221, 215, 213, 222, 220, 245, 119,\n",
       "        167,  56],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   4,   0,   0,  55,\n",
       "        236, 228, 230, 228, 240, 232, 213, 218, 223, 234, 217, 217, 209,\n",
       "         92,   0],\n",
       "       [  0,   0,   1,   4,   6,   7,   2,   0,   0,   0,   0,   0, 237,\n",
       "        226, 217, 223, 222, 219, 222, 221, 216, 223, 229, 215, 218, 255,\n",
       "         77,   0],\n",
       "       [  0,   3,   0,   0,   0,   0,   0,   0,   0,  62, 145, 204, 228,\n",
       "        207, 213, 221, 218, 208, 211, 218, 224, 223, 219, 215, 224, 244,\n",
       "        159,   0],\n",
       "       [  0,   0,   0,   0,  18,  44,  82, 107, 189, 228, 220, 222, 217,\n",
       "        226, 200, 205, 211, 230, 224, 234, 176, 188, 250, 248, 233, 238,\n",
       "        215,   0],\n",
       "       [  0,  57, 187, 208, 224, 221, 224, 208, 204, 214, 208, 209, 200,\n",
       "        159, 245, 193, 206, 223, 255, 255, 221, 234, 221, 211, 220, 232,\n",
       "        246,   0],\n",
       "       [  3, 202, 228, 224, 221, 211, 211, 214, 205, 205, 205, 220, 240,\n",
       "         80, 150, 255, 229, 221, 188, 154, 191, 210, 204, 209, 222, 228,\n",
       "        225,   0],\n",
       "       [ 98, 233, 198, 210, 222, 229, 229, 234, 249, 220, 194, 215, 217,\n",
       "        241,  65,  73, 106, 117, 168, 219, 221, 215, 217, 223, 223, 224,\n",
       "        229,  29],\n",
       "       [ 75, 204, 212, 204, 193, 205, 211, 225, 216, 185, 197, 206, 198,\n",
       "        213, 240, 195, 227, 245, 239, 223, 218, 212, 209, 222, 220, 221,\n",
       "        230,  67],\n",
       "       [ 48, 203, 183, 194, 213, 197, 185, 190, 194, 192, 202, 214, 219,\n",
       "        221, 220, 236, 225, 216, 199, 206, 186, 181, 177, 172, 181, 205,\n",
       "        206, 115],\n",
       "       [  0, 122, 219, 193, 179, 171, 183, 196, 204, 210, 213, 207, 211,\n",
       "        210, 200, 196, 194, 191, 195, 191, 198, 192, 176, 156, 167, 177,\n",
       "        210,  92],\n",
       "       [  0,   0,  74, 189, 212, 191, 175, 172, 175, 181, 185, 188, 189,\n",
       "        188, 193, 198, 204, 209, 210, 210, 211, 188, 188, 194, 192, 216,\n",
       "        170,   0],\n",
       "       [  2,   0,   0,   0,  66, 200, 222, 237, 239, 242, 246, 243, 244,\n",
       "        221, 220, 193, 191, 179, 182, 182, 181, 176, 166, 168,  99,  58,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  40,  61,  44,  72,  41,  35,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "JVlroXRZ2Cu1",
    "outputId": "119fd8d0-717e-4738-92e6-564fa9b9b0f3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "YZMShp672Fwa",
    "outputId": "df987091-7445-4a12-9e63-16281d77f584"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.00392157, 0.        , 0.        ,\n",
       "        0.05098039, 0.28627451, 0.        , 0.        , 0.00392157,\n",
       "        0.01568627, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.00392157, 0.00392157, 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.01176471, 0.        , 0.14117647,\n",
       "        0.53333333, 0.49803922, 0.24313725, 0.21176471, 0.        ,\n",
       "        0.        , 0.        , 0.00392157, 0.01176471, 0.01568627,\n",
       "        0.        , 0.        , 0.01176471],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.02352941, 0.        , 0.4       ,\n",
       "        0.8       , 0.69019608, 0.5254902 , 0.56470588, 0.48235294,\n",
       "        0.09019608, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.04705882, 0.03921569, 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.60784314,\n",
       "        0.9254902 , 0.81176471, 0.69803922, 0.41960784, 0.61176471,\n",
       "        0.63137255, 0.42745098, 0.25098039, 0.09019608, 0.30196078,\n",
       "        0.50980392, 0.28235294, 0.05882353],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.00392157, 0.        , 0.27058824, 0.81176471,\n",
       "        0.8745098 , 0.85490196, 0.84705882, 0.84705882, 0.63921569,\n",
       "        0.49803922, 0.4745098 , 0.47843137, 0.57254902, 0.55294118,\n",
       "        0.34509804, 0.6745098 , 0.25882353],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.00392157,\n",
       "        0.00392157, 0.00392157, 0.        , 0.78431373, 0.90980392,\n",
       "        0.90980392, 0.91372549, 0.89803922, 0.8745098 , 0.8745098 ,\n",
       "        0.84313725, 0.83529412, 0.64313725, 0.49803922, 0.48235294,\n",
       "        0.76862745, 0.89803922, 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.71764706, 0.88235294,\n",
       "        0.84705882, 0.8745098 , 0.89411765, 0.92156863, 0.89019608,\n",
       "        0.87843137, 0.87058824, 0.87843137, 0.86666667, 0.8745098 ,\n",
       "        0.96078431, 0.67843137, 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.75686275, 0.89411765,\n",
       "        0.85490196, 0.83529412, 0.77647059, 0.70588235, 0.83137255,\n",
       "        0.82352941, 0.82745098, 0.83529412, 0.8745098 , 0.8627451 ,\n",
       "        0.95294118, 0.79215686, 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.00392157,\n",
       "        0.01176471, 0.        , 0.04705882, 0.85882353, 0.8627451 ,\n",
       "        0.83137255, 0.85490196, 0.75294118, 0.6627451 , 0.89019608,\n",
       "        0.81568627, 0.85490196, 0.87843137, 0.83137255, 0.88627451,\n",
       "        0.77254902, 0.81960784, 0.20392157],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.02352941, 0.        , 0.38823529, 0.95686275, 0.87058824,\n",
       "        0.8627451 , 0.85490196, 0.79607843, 0.77647059, 0.86666667,\n",
       "        0.84313725, 0.83529412, 0.87058824, 0.8627451 , 0.96078431,\n",
       "        0.46666667, 0.65490196, 0.21960784],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.01568627,\n",
       "        0.        , 0.        , 0.21568627, 0.9254902 , 0.89411765,\n",
       "        0.90196078, 0.89411765, 0.94117647, 0.90980392, 0.83529412,\n",
       "        0.85490196, 0.8745098 , 0.91764706, 0.85098039, 0.85098039,\n",
       "        0.81960784, 0.36078431, 0.        ],\n",
       "       [0.        , 0.        , 0.00392157, 0.01568627, 0.02352941,\n",
       "        0.02745098, 0.00784314, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.92941176, 0.88627451, 0.85098039,\n",
       "        0.8745098 , 0.87058824, 0.85882353, 0.87058824, 0.86666667,\n",
       "        0.84705882, 0.8745098 , 0.89803922, 0.84313725, 0.85490196,\n",
       "        1.        , 0.30196078, 0.        ],\n",
       "       [0.        , 0.01176471, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.24313725,\n",
       "        0.56862745, 0.8       , 0.89411765, 0.81176471, 0.83529412,\n",
       "        0.86666667, 0.85490196, 0.81568627, 0.82745098, 0.85490196,\n",
       "        0.87843137, 0.8745098 , 0.85882353, 0.84313725, 0.87843137,\n",
       "        0.95686275, 0.62352941, 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.07058824,\n",
       "        0.17254902, 0.32156863, 0.41960784, 0.74117647, 0.89411765,\n",
       "        0.8627451 , 0.87058824, 0.85098039, 0.88627451, 0.78431373,\n",
       "        0.80392157, 0.82745098, 0.90196078, 0.87843137, 0.91764706,\n",
       "        0.69019608, 0.7372549 , 0.98039216, 0.97254902, 0.91372549,\n",
       "        0.93333333, 0.84313725, 0.        ],\n",
       "       [0.        , 0.22352941, 0.73333333, 0.81568627, 0.87843137,\n",
       "        0.86666667, 0.87843137, 0.81568627, 0.8       , 0.83921569,\n",
       "        0.81568627, 0.81960784, 0.78431373, 0.62352941, 0.96078431,\n",
       "        0.75686275, 0.80784314, 0.8745098 , 1.        , 1.        ,\n",
       "        0.86666667, 0.91764706, 0.86666667, 0.82745098, 0.8627451 ,\n",
       "        0.90980392, 0.96470588, 0.        ],\n",
       "       [0.01176471, 0.79215686, 0.89411765, 0.87843137, 0.86666667,\n",
       "        0.82745098, 0.82745098, 0.83921569, 0.80392157, 0.80392157,\n",
       "        0.80392157, 0.8627451 , 0.94117647, 0.31372549, 0.58823529,\n",
       "        1.        , 0.89803922, 0.86666667, 0.7372549 , 0.60392157,\n",
       "        0.74901961, 0.82352941, 0.8       , 0.81960784, 0.87058824,\n",
       "        0.89411765, 0.88235294, 0.        ],\n",
       "       [0.38431373, 0.91372549, 0.77647059, 0.82352941, 0.87058824,\n",
       "        0.89803922, 0.89803922, 0.91764706, 0.97647059, 0.8627451 ,\n",
       "        0.76078431, 0.84313725, 0.85098039, 0.94509804, 0.25490196,\n",
       "        0.28627451, 0.41568627, 0.45882353, 0.65882353, 0.85882353,\n",
       "        0.86666667, 0.84313725, 0.85098039, 0.8745098 , 0.8745098 ,\n",
       "        0.87843137, 0.89803922, 0.11372549],\n",
       "       [0.29411765, 0.8       , 0.83137255, 0.8       , 0.75686275,\n",
       "        0.80392157, 0.82745098, 0.88235294, 0.84705882, 0.7254902 ,\n",
       "        0.77254902, 0.80784314, 0.77647059, 0.83529412, 0.94117647,\n",
       "        0.76470588, 0.89019608, 0.96078431, 0.9372549 , 0.8745098 ,\n",
       "        0.85490196, 0.83137255, 0.81960784, 0.87058824, 0.8627451 ,\n",
       "        0.86666667, 0.90196078, 0.2627451 ],\n",
       "       [0.18823529, 0.79607843, 0.71764706, 0.76078431, 0.83529412,\n",
       "        0.77254902, 0.7254902 , 0.74509804, 0.76078431, 0.75294118,\n",
       "        0.79215686, 0.83921569, 0.85882353, 0.86666667, 0.8627451 ,\n",
       "        0.9254902 , 0.88235294, 0.84705882, 0.78039216, 0.80784314,\n",
       "        0.72941176, 0.70980392, 0.69411765, 0.6745098 , 0.70980392,\n",
       "        0.80392157, 0.80784314, 0.45098039],\n",
       "       [0.        , 0.47843137, 0.85882353, 0.75686275, 0.70196078,\n",
       "        0.67058824, 0.71764706, 0.76862745, 0.8       , 0.82352941,\n",
       "        0.83529412, 0.81176471, 0.82745098, 0.82352941, 0.78431373,\n",
       "        0.76862745, 0.76078431, 0.74901961, 0.76470588, 0.74901961,\n",
       "        0.77647059, 0.75294118, 0.69019608, 0.61176471, 0.65490196,\n",
       "        0.69411765, 0.82352941, 0.36078431],\n",
       "       [0.        , 0.        , 0.29019608, 0.74117647, 0.83137255,\n",
       "        0.74901961, 0.68627451, 0.6745098 , 0.68627451, 0.70980392,\n",
       "        0.7254902 , 0.7372549 , 0.74117647, 0.7372549 , 0.75686275,\n",
       "        0.77647059, 0.8       , 0.81960784, 0.82352941, 0.82352941,\n",
       "        0.82745098, 0.7372549 , 0.7372549 , 0.76078431, 0.75294118,\n",
       "        0.84705882, 0.66666667, 0.        ],\n",
       "       [0.00784314, 0.        , 0.        , 0.        , 0.25882353,\n",
       "        0.78431373, 0.87058824, 0.92941176, 0.9372549 , 0.94901961,\n",
       "        0.96470588, 0.95294118, 0.95686275, 0.86666667, 0.8627451 ,\n",
       "        0.75686275, 0.74901961, 0.70196078, 0.71372549, 0.71372549,\n",
       "        0.70980392, 0.69019608, 0.65098039, 0.65882353, 0.38823529,\n",
       "        0.22745098, 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.15686275, 0.23921569, 0.17254902,\n",
       "        0.28235294, 0.16078431, 0.1372549 , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X = train_X / 255.\n",
    "test_X = test_X / 255.\n",
    "\n",
    "train_X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k3qdb5AH2RiK"
   },
   "outputs": [],
   "source": [
    "# no need if i use 'sparse categorical crossentropy'\n",
    "#train_Y = tf.keras.utils.to_categorical(train_Y,num_classes=3)\n",
    "#test_Y = tf.keras.utils.to_categorical(test_Y,num_classes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "colab_type": "code",
    "id": "9U7cgCrH3F0R",
    "outputId": "e51b0ac3-effd-49c6-ffeb-5c6547c219d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 101,770\n",
      "Trainable params: 101,770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "                             tf.keras.layers.Flatten(input_shape=(28,28)),\n",
    "                             tf.keras.layers.Dense(units=128,activation='relu'),\n",
    "                             tf.keras.layers.Dense(units=10,activation='softmax')\n",
    "])\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "XmmC4sM43oqF",
    "outputId": "313c2291-29dc-4425-a49a-724ee3e3faa0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 45000 samples, validate on 15000 samples\n",
      "Epoch 1/250\n",
      "45000/45000 [==============================] - 4s 85us/sample - loss: 0.5230 - accuracy: 0.8152 - val_loss: 0.4891 - val_accuracy: 0.8299\n",
      "Epoch 2/250\n",
      "45000/45000 [==============================] - 3s 75us/sample - loss: 0.3960 - accuracy: 0.8576 - val_loss: 0.3857 - val_accuracy: 0.8613\n",
      "Epoch 3/250\n",
      "45000/45000 [==============================] - 3s 75us/sample - loss: 0.3523 - accuracy: 0.8732 - val_loss: 0.3617 - val_accuracy: 0.8685\n",
      "Epoch 4/250\n",
      "45000/45000 [==============================] - 3s 73us/sample - loss: 0.3234 - accuracy: 0.8819 - val_loss: 0.3782 - val_accuracy: 0.8635\n",
      "Epoch 5/250\n",
      "45000/45000 [==============================] - 4s 82us/sample - loss: 0.3038 - accuracy: 0.8898 - val_loss: 0.3435 - val_accuracy: 0.8775\n",
      "Epoch 6/250\n",
      "45000/45000 [==============================] - 3s 75us/sample - loss: 0.2885 - accuracy: 0.8942 - val_loss: 0.3420 - val_accuracy: 0.8793\n",
      "Epoch 7/250\n",
      "45000/45000 [==============================] - 3s 73us/sample - loss: 0.2771 - accuracy: 0.8975 - val_loss: 0.3484 - val_accuracy: 0.8741\n",
      "Epoch 8/250\n",
      "45000/45000 [==============================] - 3s 72us/sample - loss: 0.2619 - accuracy: 0.9037 - val_loss: 0.3636 - val_accuracy: 0.8727\n",
      "Epoch 9/250\n",
      "45000/45000 [==============================] - 3s 76us/sample - loss: 0.2519 - accuracy: 0.9068 - val_loss: 0.3580 - val_accuracy: 0.8683\n",
      "Epoch 10/250\n",
      "45000/45000 [==============================] - 3s 71us/sample - loss: 0.2424 - accuracy: 0.9108 - val_loss: 0.3296 - val_accuracy: 0.8856\n",
      "Epoch 11/250\n",
      "45000/45000 [==============================] - 3s 76us/sample - loss: 0.2339 - accuracy: 0.9137 - val_loss: 0.3209 - val_accuracy: 0.8879\n",
      "Epoch 12/250\n",
      "45000/45000 [==============================] - 3s 72us/sample - loss: 0.2255 - accuracy: 0.9164 - val_loss: 0.3572 - val_accuracy: 0.8756\n",
      "Epoch 13/250\n",
      "45000/45000 [==============================] - 3s 73us/sample - loss: 0.2191 - accuracy: 0.9186 - val_loss: 0.3202 - val_accuracy: 0.8886\n",
      "Epoch 14/250\n",
      "45000/45000 [==============================] - 3s 76us/sample - loss: 0.2096 - accuracy: 0.9216 - val_loss: 0.3290 - val_accuracy: 0.8883\n",
      "Epoch 15/250\n",
      "45000/45000 [==============================] - 4s 82us/sample - loss: 0.2030 - accuracy: 0.9232 - val_loss: 0.3366 - val_accuracy: 0.8847\n",
      "Epoch 16/250\n",
      "45000/45000 [==============================] - 3s 75us/sample - loss: 0.1994 - accuracy: 0.9260 - val_loss: 0.3337 - val_accuracy: 0.8909\n",
      "Epoch 17/250\n",
      "45000/45000 [==============================] - 3s 76us/sample - loss: 0.1896 - accuracy: 0.9276 - val_loss: 0.3501 - val_accuracy: 0.8881\n",
      "Epoch 18/250\n",
      "45000/45000 [==============================] - 4s 78us/sample - loss: 0.1856 - accuracy: 0.9301 - val_loss: 0.3336 - val_accuracy: 0.8893\n",
      "Epoch 19/250\n",
      "45000/45000 [==============================] - 3s 76us/sample - loss: 0.1796 - accuracy: 0.9332 - val_loss: 0.3612 - val_accuracy: 0.8837\n",
      "Epoch 20/250\n",
      "45000/45000 [==============================] - 3s 74us/sample - loss: 0.1754 - accuracy: 0.9344 - val_loss: 0.3601 - val_accuracy: 0.8889\n",
      "Epoch 21/250\n",
      "45000/45000 [==============================] - 4s 81us/sample - loss: 0.1680 - accuracy: 0.9366 - val_loss: 0.3504 - val_accuracy: 0.8909\n",
      "Epoch 22/250\n",
      "45000/45000 [==============================] - 4s 81us/sample - loss: 0.1651 - accuracy: 0.9384 - val_loss: 0.3887 - val_accuracy: 0.8775\n",
      "Epoch 23/250\n",
      "45000/45000 [==============================] - 3s 77us/sample - loss: 0.1581 - accuracy: 0.9400 - val_loss: 0.3667 - val_accuracy: 0.8850\n",
      "Epoch 24/250\n",
      "45000/45000 [==============================] - 3s 74us/sample - loss: 0.1576 - accuracy: 0.9412 - val_loss: 0.3645 - val_accuracy: 0.8890\n",
      "Epoch 25/250\n",
      "45000/45000 [==============================] - 3s 74us/sample - loss: 0.1528 - accuracy: 0.9429 - val_loss: 0.3579 - val_accuracy: 0.8933\n",
      "Epoch 26/250\n",
      "45000/45000 [==============================] - 3s 72us/sample - loss: 0.1474 - accuracy: 0.9442 - val_loss: 0.3573 - val_accuracy: 0.8925\n",
      "Epoch 27/250\n",
      "45000/45000 [==============================] - 3s 72us/sample - loss: 0.1446 - accuracy: 0.9457 - val_loss: 0.3733 - val_accuracy: 0.8941\n",
      "Epoch 28/250\n",
      "45000/45000 [==============================] - 3s 73us/sample - loss: 0.1380 - accuracy: 0.9488 - val_loss: 0.3880 - val_accuracy: 0.8930\n",
      "Epoch 29/250\n",
      "45000/45000 [==============================] - 3s 75us/sample - loss: 0.1367 - accuracy: 0.9487 - val_loss: 0.4051 - val_accuracy: 0.8837\n",
      "Epoch 30/250\n",
      "45000/45000 [==============================] - 3s 77us/sample - loss: 0.1322 - accuracy: 0.9506 - val_loss: 0.3863 - val_accuracy: 0.8890\n",
      "Epoch 31/250\n",
      "45000/45000 [==============================] - 3s 69us/sample - loss: 0.1291 - accuracy: 0.9508 - val_loss: 0.4001 - val_accuracy: 0.8886\n",
      "Epoch 32/250\n",
      "45000/45000 [==============================] - 3s 73us/sample - loss: 0.1288 - accuracy: 0.9512 - val_loss: 0.4246 - val_accuracy: 0.8817\n",
      "Epoch 33/250\n",
      "45000/45000 [==============================] - 3s 76us/sample - loss: 0.1230 - accuracy: 0.9533 - val_loss: 0.4027 - val_accuracy: 0.8935\n",
      "Epoch 34/250\n",
      "45000/45000 [==============================] - 3s 75us/sample - loss: 0.1209 - accuracy: 0.9545 - val_loss: 0.3922 - val_accuracy: 0.8945\n",
      "Epoch 35/250\n",
      "45000/45000 [==============================] - 3s 75us/sample - loss: 0.1182 - accuracy: 0.9555 - val_loss: 0.4393 - val_accuracy: 0.8857\n",
      "Epoch 36/250\n",
      "45000/45000 [==============================] - 3s 72us/sample - loss: 0.1163 - accuracy: 0.9570 - val_loss: 0.4223 - val_accuracy: 0.8913\n",
      "Epoch 37/250\n",
      "45000/45000 [==============================] - 3s 76us/sample - loss: 0.1120 - accuracy: 0.9586 - val_loss: 0.4210 - val_accuracy: 0.8917\n",
      "Epoch 38/250\n",
      "45000/45000 [==============================] - 3s 76us/sample - loss: 0.1150 - accuracy: 0.9573 - val_loss: 0.4419 - val_accuracy: 0.8887\n",
      "Epoch 39/250\n",
      "45000/45000 [==============================] - 3s 74us/sample - loss: 0.1089 - accuracy: 0.9600 - val_loss: 0.4199 - val_accuracy: 0.8949\n",
      "Epoch 40/250\n",
      "45000/45000 [==============================] - 3s 76us/sample - loss: 0.1062 - accuracy: 0.9602 - val_loss: 0.4378 - val_accuracy: 0.8883\n",
      "Epoch 41/250\n",
      "45000/45000 [==============================] - 3s 74us/sample - loss: 0.1046 - accuracy: 0.9610 - val_loss: 0.4342 - val_accuracy: 0.8933\n",
      "Epoch 42/250\n",
      "45000/45000 [==============================] - 3s 74us/sample - loss: 0.1036 - accuracy: 0.9624 - val_loss: 0.4449 - val_accuracy: 0.8879\n",
      "Epoch 43/250\n",
      "45000/45000 [==============================] - 3s 73us/sample - loss: 0.0973 - accuracy: 0.9640 - val_loss: 0.4634 - val_accuracy: 0.8915\n",
      "Epoch 44/250\n",
      "45000/45000 [==============================] - 3s 75us/sample - loss: 0.1005 - accuracy: 0.9624 - val_loss: 0.4634 - val_accuracy: 0.8881\n",
      "Epoch 45/250\n",
      "45000/45000 [==============================] - 3s 71us/sample - loss: 0.0953 - accuracy: 0.9650 - val_loss: 0.4558 - val_accuracy: 0.8891\n",
      "Epoch 46/250\n",
      "45000/45000 [==============================] - 3s 71us/sample - loss: 0.0954 - accuracy: 0.9646 - val_loss: 0.4929 - val_accuracy: 0.8825\n",
      "Epoch 47/250\n",
      "45000/45000 [==============================] - 3s 69us/sample - loss: 0.0895 - accuracy: 0.9668 - val_loss: 0.4872 - val_accuracy: 0.8899\n",
      "Epoch 48/250\n",
      "45000/45000 [==============================] - 3s 68us/sample - loss: 0.0891 - accuracy: 0.9668 - val_loss: 0.4889 - val_accuracy: 0.8849\n",
      "Epoch 49/250\n",
      "45000/45000 [==============================] - 3s 76us/sample - loss: 0.0914 - accuracy: 0.9664 - val_loss: 0.5057 - val_accuracy: 0.8836\n",
      "Epoch 50/250\n",
      "45000/45000 [==============================] - 3s 77us/sample - loss: 0.0864 - accuracy: 0.9676 - val_loss: 0.5160 - val_accuracy: 0.8823\n",
      "Epoch 51/250\n",
      "45000/45000 [==============================] - 3s 73us/sample - loss: 0.0847 - accuracy: 0.9694 - val_loss: 0.5053 - val_accuracy: 0.8903\n",
      "Epoch 52/250\n",
      "45000/45000 [==============================] - 3s 73us/sample - loss: 0.0846 - accuracy: 0.9683 - val_loss: 0.5059 - val_accuracy: 0.8882\n",
      "Epoch 53/250\n",
      "45000/45000 [==============================] - 3s 71us/sample - loss: 0.0819 - accuracy: 0.9690 - val_loss: 0.5297 - val_accuracy: 0.8863\n",
      "Epoch 54/250\n",
      "45000/45000 [==============================] - 3s 72us/sample - loss: 0.0800 - accuracy: 0.9699 - val_loss: 0.5195 - val_accuracy: 0.8831\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/250\n",
      "45000/45000 [==============================] - 3s 71us/sample - loss: 0.0790 - accuracy: 0.9694 - val_loss: 0.5489 - val_accuracy: 0.8861\n",
      "Epoch 56/250\n",
      "45000/45000 [==============================] - 3s 71us/sample - loss: 0.0781 - accuracy: 0.9702 - val_loss: 0.5339 - val_accuracy: 0.8853\n",
      "Epoch 57/250\n",
      "45000/45000 [==============================] - 3s 71us/sample - loss: 0.0769 - accuracy: 0.9722 - val_loss: 0.5360 - val_accuracy: 0.8870\n",
      "Epoch 58/250\n",
      "45000/45000 [==============================] - 3s 71us/sample - loss: 0.0760 - accuracy: 0.9717 - val_loss: 0.5666 - val_accuracy: 0.8877\n",
      "Epoch 59/250\n",
      "45000/45000 [==============================] - 3s 73us/sample - loss: 0.0719 - accuracy: 0.9735 - val_loss: 0.6031 - val_accuracy: 0.8787\n",
      "Epoch 60/250\n",
      "45000/45000 [==============================] - 3s 71us/sample - loss: 0.0736 - accuracy: 0.9724 - val_loss: 0.5727 - val_accuracy: 0.8814\n",
      "Epoch 61/250\n",
      "45000/45000 [==============================] - 3s 72us/sample - loss: 0.0724 - accuracy: 0.9731 - val_loss: 0.5578 - val_accuracy: 0.8876\n",
      "Epoch 62/250\n",
      "45000/45000 [==============================] - 4s 80us/sample - loss: 0.0678 - accuracy: 0.9751 - val_loss: 0.5689 - val_accuracy: 0.8882\n",
      "Epoch 63/250\n",
      "45000/45000 [==============================] - 3s 71us/sample - loss: 0.0703 - accuracy: 0.9745 - val_loss: 0.5765 - val_accuracy: 0.8896\n",
      "Epoch 64/250\n",
      "45000/45000 [==============================] - 3s 75us/sample - loss: 0.0681 - accuracy: 0.9746 - val_loss: 0.6024 - val_accuracy: 0.8831\n",
      "Epoch 65/250\n",
      "45000/45000 [==============================] - 3s 74us/sample - loss: 0.0671 - accuracy: 0.9755 - val_loss: 0.5779 - val_accuracy: 0.8905\n",
      "Epoch 66/250\n",
      "45000/45000 [==============================] - 3s 70us/sample - loss: 0.0647 - accuracy: 0.9755 - val_loss: 0.5825 - val_accuracy: 0.8875\n",
      "Epoch 67/250\n",
      "45000/45000 [==============================] - 3s 73us/sample - loss: 0.0644 - accuracy: 0.9759 - val_loss: 0.5953 - val_accuracy: 0.8888\n",
      "Epoch 68/250\n",
      "45000/45000 [==============================] - 3s 76us/sample - loss: 0.0650 - accuracy: 0.9764 - val_loss: 0.5735 - val_accuracy: 0.8879\n",
      "Epoch 69/250\n",
      "45000/45000 [==============================] - 4s 78us/sample - loss: 0.0633 - accuracy: 0.9757 - val_loss: 0.6162 - val_accuracy: 0.8851\n",
      "Epoch 70/250\n",
      "45000/45000 [==============================] - 3s 76us/sample - loss: 0.0595 - accuracy: 0.9780 - val_loss: 0.6019 - val_accuracy: 0.8879\n",
      "Epoch 71/250\n",
      "45000/45000 [==============================] - 3s 71us/sample - loss: 0.0616 - accuracy: 0.9762 - val_loss: 0.5916 - val_accuracy: 0.8903\n",
      "Epoch 72/250\n",
      "45000/45000 [==============================] - 3s 74us/sample - loss: 0.0594 - accuracy: 0.9781 - val_loss: 0.6443 - val_accuracy: 0.8825\n",
      "Epoch 73/250\n",
      "45000/45000 [==============================] - 3s 74us/sample - loss: 0.0590 - accuracy: 0.9782 - val_loss: 0.6105 - val_accuracy: 0.8896\n",
      "Epoch 74/250\n",
      "45000/45000 [==============================] - 4s 83us/sample - loss: 0.0584 - accuracy: 0.9785 - val_loss: 0.6807 - val_accuracy: 0.8815\n",
      "Epoch 75/250\n",
      "45000/45000 [==============================] - 4s 89us/sample - loss: 0.0589 - accuracy: 0.9782 - val_loss: 0.6552 - val_accuracy: 0.8885\n",
      "Epoch 76/250\n",
      "45000/45000 [==============================] - 4s 84us/sample - loss: 0.0552 - accuracy: 0.9799 - val_loss: 0.6194 - val_accuracy: 0.8893\n",
      "Epoch 77/250\n",
      "45000/45000 [==============================] - 3s 76us/sample - loss: 0.0554 - accuracy: 0.9800 - val_loss: 0.6789 - val_accuracy: 0.8871\n",
      "Epoch 78/250\n",
      "45000/45000 [==============================] - 4s 87us/sample - loss: 0.0542 - accuracy: 0.9794 - val_loss: 0.6353 - val_accuracy: 0.8875\n",
      "Epoch 79/250\n",
      "45000/45000 [==============================] - 3s 70us/sample - loss: 0.0552 - accuracy: 0.9798 - val_loss: 0.6351 - val_accuracy: 0.8880\n",
      "Epoch 80/250\n",
      "45000/45000 [==============================] - 3s 70us/sample - loss: 0.0558 - accuracy: 0.9794 - val_loss: 0.6587 - val_accuracy: 0.8896\n",
      "Epoch 81/250\n",
      "45000/45000 [==============================] - 4s 80us/sample - loss: 0.0524 - accuracy: 0.9812 - val_loss: 0.6666 - val_accuracy: 0.8880\n",
      "Epoch 82/250\n",
      "45000/45000 [==============================] - 3s 77us/sample - loss: 0.0525 - accuracy: 0.9803 - val_loss: 0.7048 - val_accuracy: 0.8881\n",
      "Epoch 83/250\n",
      "45000/45000 [==============================] - 4s 81us/sample - loss: 0.0532 - accuracy: 0.9798 - val_loss: 0.6804 - val_accuracy: 0.8911\n",
      "Epoch 84/250\n",
      "45000/45000 [==============================] - 3s 76us/sample - loss: 0.0503 - accuracy: 0.9814 - val_loss: 0.6877 - val_accuracy: 0.8893\n",
      "Epoch 85/250\n",
      "45000/45000 [==============================] - 3s 75us/sample - loss: 0.0508 - accuracy: 0.9808 - val_loss: 0.6875 - val_accuracy: 0.8888\n",
      "Epoch 86/250\n",
      "45000/45000 [==============================] - 3s 76us/sample - loss: 0.0508 - accuracy: 0.9816 - val_loss: 0.6893 - val_accuracy: 0.8889\n",
      "Epoch 87/250\n",
      "45000/45000 [==============================] - 3s 76us/sample - loss: 0.0452 - accuracy: 0.9835 - val_loss: 0.7173 - val_accuracy: 0.8843\n",
      "Epoch 88/250\n",
      "45000/45000 [==============================] - 3s 73us/sample - loss: 0.0507 - accuracy: 0.9814 - val_loss: 0.7317 - val_accuracy: 0.8880\n",
      "Epoch 89/250\n",
      "45000/45000 [==============================] - 3s 75us/sample - loss: 0.0484 - accuracy: 0.9817 - val_loss: 0.7038 - val_accuracy: 0.8910\n",
      "Epoch 90/250\n",
      "45000/45000 [==============================] - 3s 73us/sample - loss: 0.0444 - accuracy: 0.9840 - val_loss: 0.7097 - val_accuracy: 0.8885\n",
      "Epoch 91/250\n",
      "45000/45000 [==============================] - 3s 73us/sample - loss: 0.0500 - accuracy: 0.9815 - val_loss: 0.7027 - val_accuracy: 0.8897\n",
      "Epoch 92/250\n",
      "45000/45000 [==============================] - 3s 77us/sample - loss: 0.0463 - accuracy: 0.9828 - val_loss: 0.7330 - val_accuracy: 0.8887\n",
      "Epoch 93/250\n",
      "45000/45000 [==============================] - 3s 72us/sample - loss: 0.0473 - accuracy: 0.9822 - val_loss: 0.7416 - val_accuracy: 0.8846\n",
      "Epoch 94/250\n",
      "45000/45000 [==============================] - 3s 73us/sample - loss: 0.0416 - accuracy: 0.9848 - val_loss: 0.7703 - val_accuracy: 0.8845\n",
      "Epoch 95/250\n",
      "45000/45000 [==============================] - 3s 73us/sample - loss: 0.0475 - accuracy: 0.9828 - val_loss: 0.7598 - val_accuracy: 0.8847\n",
      "Epoch 96/250\n",
      "45000/45000 [==============================] - 3s 72us/sample - loss: 0.0428 - accuracy: 0.9845 - val_loss: 0.7613 - val_accuracy: 0.8911\n",
      "Epoch 97/250\n",
      "45000/45000 [==============================] - 3s 75us/sample - loss: 0.0496 - accuracy: 0.9820 - val_loss: 0.7563 - val_accuracy: 0.8880\n",
      "Epoch 98/250\n",
      "45000/45000 [==============================] - 4s 85us/sample - loss: 0.0432 - accuracy: 0.9843 - val_loss: 0.7855 - val_accuracy: 0.8837\n",
      "Epoch 99/250\n",
      "45000/45000 [==============================] - 4s 81us/sample - loss: 0.0392 - accuracy: 0.9857 - val_loss: 0.8146 - val_accuracy: 0.8809\n",
      "Epoch 100/250\n",
      "45000/45000 [==============================] - 4s 78us/sample - loss: 0.0463 - accuracy: 0.9832 - val_loss: 0.7641 - val_accuracy: 0.8889\n",
      "Epoch 101/250\n",
      "45000/45000 [==============================] - 3s 78us/sample - loss: 0.0396 - accuracy: 0.9857 - val_loss: 0.7735 - val_accuracy: 0.8865\n",
      "Epoch 102/250\n",
      "45000/45000 [==============================] - 3s 73us/sample - loss: 0.0432 - accuracy: 0.9841 - val_loss: 0.7674 - val_accuracy: 0.8897\n",
      "Epoch 103/250\n",
      "45000/45000 [==============================] - 3s 71us/sample - loss: 0.0408 - accuracy: 0.9847 - val_loss: 0.7958 - val_accuracy: 0.8895\n",
      "Epoch 104/250\n",
      "45000/45000 [==============================] - 4s 78us/sample - loss: 0.0420 - accuracy: 0.9849 - val_loss: 0.7604 - val_accuracy: 0.8890\n",
      "Epoch 105/250\n",
      "45000/45000 [==============================] - 3s 69us/sample - loss: 0.0371 - accuracy: 0.9864 - val_loss: 0.7845 - val_accuracy: 0.8895\n",
      "Epoch 106/250\n",
      "45000/45000 [==============================] - 3s 73us/sample - loss: 0.0421 - accuracy: 0.9841 - val_loss: 0.8364 - val_accuracy: 0.8873\n",
      "Epoch 107/250\n",
      "45000/45000 [==============================] - 3s 72us/sample - loss: 0.0397 - accuracy: 0.9859 - val_loss: 0.8151 - val_accuracy: 0.8805\n",
      "Epoch 108/250\n",
      "45000/45000 [==============================] - 3s 71us/sample - loss: 0.0368 - accuracy: 0.9867 - val_loss: 0.8285 - val_accuracy: 0.8882\n",
      "Epoch 109/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45000/45000 [==============================] - 3s 75us/sample - loss: 0.0402 - accuracy: 0.9853 - val_loss: 0.7983 - val_accuracy: 0.8874\n",
      "Epoch 110/250\n",
      "45000/45000 [==============================] - 3s 74us/sample - loss: 0.0372 - accuracy: 0.9866 - val_loss: 0.8690 - val_accuracy: 0.8825\n",
      "Epoch 111/250\n",
      "45000/45000 [==============================] - 4s 80us/sample - loss: 0.0417 - accuracy: 0.9856 - val_loss: 0.8268 - val_accuracy: 0.8802\n",
      "Epoch 112/250\n",
      "45000/45000 [==============================] - 3s 73us/sample - loss: 0.0352 - accuracy: 0.9876 - val_loss: 0.9202 - val_accuracy: 0.8803\n",
      "Epoch 113/250\n",
      "45000/45000 [==============================] - 3s 72us/sample - loss: 0.0397 - accuracy: 0.9858 - val_loss: 0.8467 - val_accuracy: 0.8839\n",
      "Epoch 114/250\n",
      "45000/45000 [==============================] - 3s 70us/sample - loss: 0.0383 - accuracy: 0.9862 - val_loss: 0.8331 - val_accuracy: 0.8892\n",
      "Epoch 115/250\n",
      "45000/45000 [==============================] - 3s 71us/sample - loss: 0.0337 - accuracy: 0.9878 - val_loss: 0.8374 - val_accuracy: 0.8888\n",
      "Epoch 116/250\n",
      "45000/45000 [==============================] - 3s 72us/sample - loss: 0.0421 - accuracy: 0.9853 - val_loss: 0.8305 - val_accuracy: 0.8881\n",
      "Epoch 117/250\n",
      "45000/45000 [==============================] - 3s 72us/sample - loss: 0.0318 - accuracy: 0.9887 - val_loss: 0.8893 - val_accuracy: 0.8817\n",
      "Epoch 118/250\n",
      "45000/45000 [==============================] - 3s 71us/sample - loss: 0.0328 - accuracy: 0.9879 - val_loss: 0.8604 - val_accuracy: 0.8869\n",
      "Epoch 119/250\n",
      "45000/45000 [==============================] - 3s 72us/sample - loss: 0.0399 - accuracy: 0.9850 - val_loss: 0.8893 - val_accuracy: 0.8882\n",
      "Epoch 120/250\n",
      "45000/45000 [==============================] - 3s 74us/sample - loss: 0.0310 - accuracy: 0.9888 - val_loss: 0.8749 - val_accuracy: 0.8834\n",
      "Epoch 121/250\n",
      " 7104/45000 [===>..........................] - ETA: 2s - loss: 0.0402 - accuracy: 0.9837"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_X,train_Y,epochs=250,validation_split=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nAg-atgQ3yV8"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "TF20_practice_ch05_mnist",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
